{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VisRec_Tutorial_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ialab-puc/VisualRecSys-Tutorial-IUI2021/blob/main/colabnotebooks/VisRec_Tutorial_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fboi--iJanPs"
      },
      "source": [
        "# Clone VisRec Tutorial repository\n",
        "!git clone https://github.com/ialab-puc/VisualRecSys-Tutorial-IUI2021.git\n",
        "# Download evaluation data\n",
        "!gdown --id 1YaCuLhGdWT1l1UfPoqnZ-56MPE21l0-5 -O /content/VisualRecSys-Tutorial-IUI2021/data/naive-profile-evaluation.csv\n",
        "!gdown --id 1ZBOkRuaCuj0_4hhShM7mUtBojNorXMSd -O /content/VisualRecSys-Tutorial-IUI2021/data/naive-user-evaluation.csv\n",
        "# Download checkpoints\n",
        "!gdown --id 1tuTzyCfPwIKzP34finJWEcpxI3UKt-Tx -O /content/VisualRecSys-Tutorial-IUI2021/checkpoints/CuratorNet_wikimedia.tar\n",
        "!gdown --id 1loMB_TfcCBqeaJqUCXHSP5F1b7KOgt6g -O /content/VisualRecSys-Tutorial-IUI2021/checkpoints/ACF_wikimedia.pt\n",
        "!gdown --id 1UfqS6lvZxx2ol74KgFn1WR6I89Gb_Xd2 -O /content/VisualRecSys-Tutorial-IUI2021/checkpoints/DVBPR_wikimedia.tar\n",
        "!gdown --id 1FfEH1wQiptx2ZwwKKaihOmo9vbDXItKm -O /content/VisualRecSys-Tutorial-IUI2021/checkpoints/VBPR_wikimedia.tar\n",
        "# Download images\n",
        "!gdown --id 1wXsmcSgsUaQs8tAHIKsriWJ-6Batn5pH -O /content/VisualRecSys-Tutorial-IUI2021/data/iui_wikimedia_images.tar.gz\n",
        "# Download embeddings\n",
        "!gdown --id 1UACSDRMQQt7XhTg96O-MkGKka-TGaxls -O /content/VisualRecSys-Tutorial-IUI2021/data/embedding-resnet50.npy\n",
        "!gdown --id 1dx1J-N-i-JwC4PTzn3_qJeOWIZYbbJen -O /content/VisualRecSys-Tutorial-IUI2021/data/embedding-resnet50-layer4.tar.gz\n",
        "# Extract files\n",
        "!tar -xf /content/VisualRecSys-Tutorial-IUI2021/data/iui_wikimedia_images.tar.gz -C /content/VisualRecSys-Tutorial-IUI2021/data\n",
        "!tar -xf /content/VisualRecSys-Tutorial-IUI2021/data/embedding-resnet50-layer4.tar.gz -C /content/VisualRecSys-Tutorial-IUI2021/data\n",
        "# Move to repository main folder\n",
        "%cd /content/VisualRecSys-Tutorial-IUI2021/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw1ZlGEwallo"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "from models import VBPR, DVBPR, ACF, CuratorNet\n",
        "from datasets.user_mode_img import ToTensor\n",
        "from utils.data import extract_embedding\n",
        "from utils.metrics import (\n",
        "    auc_exact,\n",
        "    nDCG,\n",
        "    precision,\n",
        "    recall,\n",
        "    reciprocal_rank,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrw8mf-tallq"
      },
      "source": [
        "# Evaluation procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3aKIW9Jallq"
      },
      "source": [
        "DATASET = \"Wikimedia\"\n",
        "\n",
        "# Model\n",
        "MODEL = \"CuratorNet\"\n",
        "assert MODEL in [\"VBPR\", \"DVBPR\", \"CuratorNet\", \"ACF\"]\n",
        "\n",
        "FEATURE_EXTRACTOR = \"resnet50\"\n",
        "assert FEATURE_EXTRACTOR in [\"alexnet\", \"vgg16\", \"resnet50\"]\n",
        "\n",
        "FEATURE_LAYER = \"layer4\"\n",
        "FEATURE_LAYER = FEATURE_LAYER if MODEL == \"ACF\" else \"\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRXK_N5gallr"
      },
      "source": [
        "# Mode\n",
        "# Use 'MODE_PROFILE = True' for CuratorNet-like training \n",
        "# Use 'MODE_PROFILE = False' for VBPR-like training\n",
        "MODE_PROFILE = MODEL in [\"CuratorNet\"]\n",
        "MODE_PROFILE = \"profile\" if MODE_PROFILE else \"user\"\n",
        "\n",
        "# Checkpoint (ex. 'VBPR_wikimedia')\n",
        "CHECKPOINT = f\"{MODEL}_wikimedia\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZE1ZWlzallr"
      },
      "source": [
        "# Paths (general)\n",
        "CHECKPOINT_EXT = \"pt\" if MODEL == \"ACF\" else \"tar\" \n",
        "CHECKPOINT_PATH = os.path.join(\"checkpoints\", f\"{CHECKPOINT}.{CHECKPOINT_EXT}\")\n",
        "FEATURE_EXTRACTOR = f\"{FEATURE_EXTRACTOR}-{FEATURE_LAYER}\" if FEATURE_LAYER else FEATURE_EXTRACTOR\n",
        "EMBEDDING_PATH = os.path.join(\"data\", f\"embedding-{FEATURE_EXTRACTOR}.npy\")\n",
        "EVALUATION_PATH = os.path.join(\"data\", f\"naive-{MODE_PROFILE}-evaluation.csv\")\n",
        "\n",
        "# Paths (images)\n",
        "IMAGES_DIR = os.path.join(\"data\", \"iui_wikimedia_images\")\n",
        "\n",
        "# General constants\n",
        "RNG_SEED = 0\n",
        "USE_GPU = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTRKxM-Balls"
      },
      "source": [
        "# Freezing RNG seed if needed\n",
        "if RNG_SEED is not None:\n",
        "    print(f\"\\nUsing random seed... ({RNG_SEED})\")\n",
        "    torch.manual_seed(RNG_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DosVpiIalls"
      },
      "source": [
        "# Load embedding from file\n",
        "print(f\"\\nLoading embedding from file... ({EMBEDDING_PATH})\")\n",
        "embedding = np.load(EMBEDDING_PATH, allow_pickle=True)\n",
        "\n",
        "# Extract features and \"id2index\" mapping\n",
        "print(\"\\nExtracting data into variables...\")\n",
        "features, id2index, item_index2fn = extract_embedding(embedding, verbose=True)\n",
        "print(f\">> Features shape: {features.shape}\")\n",
        "del embedding  # Release some memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWJIxftEalls"
      },
      "source": [
        "# Load evaluation dataframe\n",
        "print(\"\\nLoad evaluation dataframe\")\n",
        "evaluation_df = pd.read_csv(EVALUATION_PATH)\n",
        "# Transform lists from str to int\n",
        "string_to_list = lambda s: list(map(int, s.split()))\n",
        "evaluation_df[\"profile\"] = evaluation_df[\"profile\"].apply(\n",
        "    lambda s: string_to_list(s) if isinstance(s, str) else s,\n",
        ")\n",
        "evaluation_df[\"predict\"] = evaluation_df[\"predict\"].apply(\n",
        "    lambda s: string_to_list(s) if isinstance(s, str) else s,\n",
        ")\n",
        "# Group evaluations by profile and user\n",
        "evaluation_df[\"profile\"] = evaluation_df[\"profile\"].map(tuple)\n",
        "evaluation_df = evaluation_df.groupby([\"profile\", \"user_id\"]).agg({\"predict\": sum}).reset_index()\n",
        "evaluation_df[\"profile\"] = evaluation_df[\"profile\"].map(list)\n",
        "print(f\">> Evaluation: {evaluation_df.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yw0GH0lallv"
      },
      "source": [
        "# Create device instance\n",
        "print(\"\\nDevice initialization\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and USE_GPU else \"cpu\")\n",
        "if torch.cuda.is_available() != USE_GPU:\n",
        "    print((f\"\\nNotice: Not using GPU - \"\n",
        "           f\"Cuda available ({torch.cuda.is_available()}) \"\n",
        "           f\"does not match USE_GPU ({USE_GPU})\"\n",
        "    ))\n",
        "\n",
        "# Loading checkpoint\n",
        "if CHECKPOINT is not None:\n",
        "    print(\"\\nLoading checkpoint\")\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=torch.device(\"cpu\"))\n",
        "    if 'epoch' in checkpoint and 'accuracy' in checkpoint:\n",
        "        print(f\">> Best epoch: {checkpoint['epoch']} | Best accuracy: {checkpoint['accuracy']}\")\n",
        "    elif 'epoch' in checkpoint and 'loss' in checkpoint:\n",
        "        print(f\">> Best epoch: {checkpoint['epoch']} | Best Loss: {checkpoint['loss']}\")\n",
        "\n",
        "# Model initialization\n",
        "print(\"\\nModel initialization\")\n",
        "model = None\n",
        "checkpoint_loaded = False\n",
        "if MODEL == \"VBPR\":\n",
        "    n_users = checkpoint[\"model\"][\"gamma_users.weight\"].size(0)\n",
        "    n_items = checkpoint[\"model\"][\"gamma_items.weight\"].size(0)\n",
        "    dim_gamma = checkpoint[\"model\"][\"gamma_users.weight\"].size(1)\n",
        "    dim_theta = checkpoint[\"model\"][\"theta_users.weight\"].size(1)\n",
        "    model = VBPR(\n",
        "        n_users, n_items,  # Number of users and items\n",
        "        torch.Tensor(features),  # Pretrained visual features\n",
        "        dim_gamma, dim_theta,  # Size of internal spaces\n",
        "    ).to(device)\n",
        "elif MODEL == \"CuratorNet\":\n",
        "    model = CuratorNet(\n",
        "        torch.Tensor(features),\n",
        "        input_size=features.shape[1],\n",
        "    ).to(device)\n",
        "elif MODEL == \"ACF\":\n",
        "    model = ACF.from_checkpoint(checkpoint, device=device)\n",
        "    checkpoint_loaded = True\n",
        "elif MODEL == \"DVBPR\":\n",
        "    n_users = checkpoint[\"model\"][\"theta_users.weight\"].size(0)\n",
        "    n_items = checkpoint[\"model\"][\"gamma_items.weight\"].size(0)\n",
        "    K = checkpoint[\"model\"][\"theta_users.weight\"].size(1)\n",
        "    model = DVBPR(n_users, n_items, K=K).to(device)\n",
        "    \n",
        "# Load state dict\n",
        "if not checkpoint_loaded and CHECKPOINT is not None:\n",
        "    model.load_state_dict(checkpoint[\"model\"])\n",
        "    print('loaded')\n",
        "\n",
        "# Change model mode to eval\n",
        "print(\"\\nChanging model mode to eval\")\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehs9zIQDallw"
      },
      "source": [
        "# Predict all\n",
        "# If True, ranks every item including already consumed items\n",
        "# If False, ranks ALL - PROFILE (consumed) + PREDICT (ground truth)\n",
        "PREDICT_ALL = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps-n_6yPallw"
      },
      "source": [
        "%%time\n",
        "# Metrics\n",
        "N_EVALS = len(evaluation_df.index)\n",
        "# Area Under the Curve (AUC)\n",
        "AUC = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "# Reciprocal Rank (RR)\n",
        "RR = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "# Recall\n",
        "R20 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "R100 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "R200 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "# Precision\n",
        "P20 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "P100 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "P200 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "# Normalized discounted cumulative gain (nDCG)\n",
        "N20 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "N100 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "N200 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
        "PROFILE_SIZES = torch.zeros([N_EVALS], dtype=int, device=device)\n",
        "N_ITEMS = len(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyEaUg3dallx"
      },
      "source": [
        "if MODEL in (\"VBPR\", \"CuratorNet\"):\n",
        "    cache = model.generate_cache()\n",
        "elif MODEL == \"DVBPR\":\n",
        "    def getimg(path, tensorizer):\n",
        "        img = io.imread(path)\n",
        "        return tensorizer(img)\n",
        "    \n",
        "    imglist = {}\n",
        "    for path in tqdm(os.listdir(IMAGES_DIR)):\n",
        "        if path in item_index2fn.values():\n",
        "            img = getimg(os.path.join(IMAGES_DIR, path), ToTensor()) \n",
        "            name = path.split('.')[0]\n",
        "            imglist[id2index[name]] = img\n",
        "\n",
        "    assert len(imglist) == N_ITEMS\n",
        "    print('images loaded:', N_ITEMS)\n",
        "    cache = model.generate_cache(imglist, device=device)\n",
        "    print('generated cache: ', cache.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03uT_ntVallx"
      },
      "source": [
        "evaluation_df[\"profile\"] = evaluation_df[\"profile\"].map(tuple)\n",
        "grouped_evals = evaluation_df.groupby([\"profile\", \"user_id\"]).agg({\"predict\": sum}).reset_index()\n",
        "for i, row in tqdm(enumerate(evaluation_df.itertuples()), total=len(evaluation_df.index)):\n",
        "    # Load data into tensors\n",
        "    profile = torch.tensor(row.profile).to(device, non_blocking=True).unsqueeze(0)\n",
        "    user_id = torch.tensor([int(row.user_id)]).to(device, non_blocking=True)\n",
        "    predict = torch.tensor(row.predict).to(device, non_blocking=True)\n",
        "    # Prediction\n",
        "    if MODEL == \"ACF\":\n",
        "        acf_profile = profile + 1 # In ACF items are indexed starting at 1\n",
        "        scores = model.recommend_all(user_id, acf_profile).squeeze()\n",
        "    elif MODEL == 'DVBPR':\n",
        "        scores = model.recommend_all(user_id, imglist, cache=cache)\n",
        "    elif MODE_PROFILE == \"profile\":\n",
        "        scores = model.recommend_all(profile, cache=cache)\n",
        "    elif MODE_PROFILE == \"user\":\n",
        "        scores = model.recommend_all(user_id, cache=cache).squeeze()\n",
        "    \n",
        "    # Ranking\n",
        "    pos_of_evals = (torch.argsort(scores, descending=True)[..., None] == predict).any(-1).nonzero().flatten()\n",
        "    if not PREDICT_ALL:\n",
        "        pos_of_profi = (torch.argsort(scores, descending=True)[..., None] == profile).any(-1).nonzero().flatten()\n",
        "        # Relevant dimensions\n",
        "        _a, _b = pos_of_evals.size(0), pos_of_profi.size(0)\n",
        "        # Calculate shift for each eval item\n",
        "        shift = (pos_of_profi.expand(_a, _b) < pos_of_evals.reshape(_a, 1).expand(_a, _b)).sum(1)\n",
        "        # Apply shift\n",
        "        pos_of_evals -= shift.squeeze(0)\n",
        "    # Store metrics\n",
        "    AUC[i] = auc_exact(pos_of_evals, N_ITEMS)\n",
        "    RR[i] = reciprocal_rank(pos_of_evals)\n",
        "    R20[i] = recall(pos_of_evals, 20)\n",
        "    P20[i] = precision(pos_of_evals, 20)\n",
        "    N20[i] = nDCG(pos_of_evals, 20)\n",
        "    R100[i] = recall(pos_of_evals, 100)\n",
        "    P100[i] = precision(pos_of_evals, 100)\n",
        "    N100[i] = nDCG(pos_of_evals, 100)\n",
        "    R200[i] = recall(pos_of_evals, 200)\n",
        "    P200[i] = precision(pos_of_evals, 200)\n",
        "    N200[i] = nDCG(pos_of_evals, 200)\n",
        "    PROFILE_SIZES[i] = len(row.profile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9s83PMDally"
      },
      "source": [
        "# Display stats\n",
        "print(f\"AVG AUC = {AUC.mean()}\")\n",
        "print(f\"AVG RR = {RR.mean()}\")\n",
        "print(f\"AVG R20 = {R20.mean()}\")\n",
        "print(f\"AVG P20 = {P20.mean()}\")\n",
        "print(f\"AVG NDCG20 = {N20.mean()}\")\n",
        "print(f\"AVG R100 = {R100.mean()}\")\n",
        "print(f\"AVG P100 = {P100.mean()}\")\n",
        "print(f\"AVG NDCG100 = {N100.mean()}\")\n",
        "print(f\"AVG R200 = {R200.mean()}\")\n",
        "print(f\"AVG P200 = {P200.mean()}\")\n",
        "print(f\"AVG NDCG200 = {N200.mean()}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWx4Bmx8allz"
      },
      "source": [
        "## Relevant plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Mx3d1Wallz"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def smart_group(value):\n",
        "    if value == 0:\n",
        "        return 0\n",
        "    digits = int(np.log10(value)) + 1\n",
        "    return (10**(digits - 1)) * (value // (10**(digits - 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipacpHrlallz"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "metrics_data = [\n",
        "    [\n",
        "        PROFILE_SIZES[i].item(), AUC[i].item(), RR[i].item(),\n",
        "        R20[i].item(), P20[i].item(), N20[i].item(),\n",
        "        R100[i].item(), P100[i].item(), N100[i].item(),\n",
        "    ]\n",
        "    for i in range(N_EVALS)\n",
        "]\n",
        "metrics_df = pd.DataFrame(metrics_data, columns=[\n",
        "    \"PROFILE_SIZES\", \"AUC\", \"RR\",\n",
        "    \"R20\", \"P20\", \"N20\",\n",
        "    \"R100\", \"P100\", \"N100\",\n",
        "])\n",
        "metrics_df[\"PROFILE_SIZES_STEPS\"] = metrics_df[\"PROFILE_SIZES\"].map(smart_group)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70mtQoVHallz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Metric\n",
        "METRIC = \"AUC\"\n",
        "# Profile size range\n",
        "metrics_df_plot = metrics_df.copy()\n",
        "metrics_df_plot = metrics_df_plot[\n",
        "    (metrics_df_plot[\"PROFILE_SIZES_STEPS\"] >= 0) & (metrics_df_plot[\"PROFILE_SIZES_STEPS\"] < 100)\n",
        "]\n",
        "# Plot METRIC distribution across users grouped by profile size\n",
        "plt.figure(figsize=(24, 9))\n",
        "ax = sns.violinplot(x=\"PROFILE_SIZES_STEPS\", y=METRIC, data=metrics_df_plot, inner=None)\n",
        "if DATASET != \"Pinterest\":\n",
        "    ax = sns.swarmplot(x=\"PROFILE_SIZES_STEPS\", y=METRIC, data=metrics_df_plot, color=\"black\", edgecolor=\"gray\", size=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHlxp-3zall0"
      },
      "source": [
        "# Area Under the Curve distribution across users\n",
        "metrics_df[\"AUC\"].plot.box(sym=\"r+\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XZ0teI1all0"
      },
      "source": [
        "# First relevant item position (1 / reciprocal_rank) distribution across users\n",
        "# Line marks the 10% of the dataset\n",
        "graph = (1 / metrics_df[\"RR\"]).plot.box(sym=\"r+\")\n",
        "plt.ylim(0, features.shape[0])\n",
        "graph.axhline(features.shape[0] / 10, color=\"red\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO2hHFbMall0"
      },
      "source": [
        "# First relevant item position (1 / reciprocal_rank) histogram\n",
        "graph = (1 / metrics_df[\"RR\"]).plot.hist(bins=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkLBGJRRall0"
      },
      "source": [
        "## Results inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWh2rPXVall0"
      },
      "source": [
        "ROW = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fX8rvjxall0"
      },
      "source": [
        "# Row in evaluation dataframe\n",
        "row = evaluation_df.iloc[ROW]\n",
        "\n",
        "# Load data into tensors\n",
        "profile = torch.tensor(row.profile).to(device, non_blocking=True).unsqueeze(0)\n",
        "user_id = torch.tensor([int(row.user_id)]).to(device, non_blocking=True)\n",
        "predict = torch.tensor(row.predict).to(device, non_blocking=True)\n",
        "# Prediction\n",
        "if MODEL == \"ACF\":\n",
        "    acf_profile = profile + 1\n",
        "    scores = model.recommend_all(user_id, acf_profile).squeeze()\n",
        "elif MODEL == 'DVBPR':\n",
        "    scores = model.recommend_all(user_id, imglist, cache=cache).squeeze()\n",
        "elif MODE_PROFILE == \"profile\":\n",
        "    scores = model.recommend_all(profile)\n",
        "elif MODE_PROFILE == \"user\":\n",
        "    scores = model.recommend_all(user_id).squeeze()\n",
        "# Ranking\n",
        "pos_of_evals = (torch.argsort(scores, descending=True)[..., None] == predict).any(-1).nonzero().flatten()\n",
        "if not PREDICT_ALL:\n",
        "    pos_of_profi = (torch.argsort(scores, descending=True)[..., None] == profile).any(-1).nonzero().flatten()\n",
        "    pos_of_evals -= (pos_of_profi < pos_of_evals).sum()\n",
        "\n",
        "# Display metrics\n",
        "print(f\"| {'-' * 15} | {'-' * 7} |\")\n",
        "print(f\"| {'Metric':^15} | {'Score':^7} |\")\n",
        "print(f\"| {'-' * 15} | {'-' * 7} |\")\n",
        "print(f\"| {'AUC':^15} | {auc_exact(pos_of_evals, N_ITEMS):.5f} |\")\n",
        "print(f\"| {'RR':^15} | {reciprocal_rank(pos_of_evals):.5f} |\")\n",
        "for k in [20, 100, 500]:\n",
        "    print(f\"| {'-' * 15} | {'-' * 7} |\")\n",
        "    print(f\"| {f'Recall@{k}':^15} | {recall(pos_of_evals, k):.5f} |\")\n",
        "    print(f\"| {f'Precision@{k}':^15} | {precision(pos_of_evals, k):.5f} |\")\n",
        "    print(f\"| {f'nDCG@{k}':^15} | {nDCG(pos_of_evals, k):.5f} |\")\n",
        "print(f\"| {'-' * 15} | {'-' * 7} |\")\n",
        "\n",
        "# Profile and prediction\n",
        "profile = profile.cpu().numpy().flatten()\n",
        "predict = predict.cpu().numpy().flatten()\n",
        "# Ranking\n",
        "K = 20\n",
        "ranking = torch.argsort(scores, descending=True).cpu().numpy().flatten()\n",
        "if not PREDICT_ALL:\n",
        "    ranking = ranking[(~np.isin(ranking, profile)) | (np.isin(ranking, predict))]\n",
        "ranking = ranking[:K]\n",
        "print()\n",
        "print(f\"Size of profile: {profile.size}\")\n",
        "print(f\"Position of actual items: {pos_of_evals.cpu().numpy()}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLdfR_Jtall1",
        "scrolled": false
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "COLUMNS = 10\n",
        "ELEMENTS = {\n",
        "    \"Consumed\": profile,\n",
        "    \"Recommendation\": ranking,\n",
        "    \"Ground truth\": predict,\n",
        "}\n",
        "SHOW_FILENAME = False\n",
        "\n",
        "for label, items in ELEMENTS.items():\n",
        "    n_rows = ((len(items) - 1) // COLUMNS + 1)\n",
        "    fig = plt.figure(figsize=(COLUMNS * 2, 4 * n_rows))\n",
        "    plt.title(f\"{label.title()} (n={len(items)})\")\n",
        "    plt.axis(\"off\")\n",
        "    for i, img_id in enumerate(items, start=1):\n",
        "        img_fn = item_index2fn[img_id]\n",
        "        image = mpimg.imread(os.path.join(IMAGES_DIR, img_fn))\n",
        "        ax = fig.add_subplot(n_rows, COLUMNS, i)\n",
        "        if SHOW_FILENAME:\n",
        "            ax.set_title(img_fn)\n",
        "        if label == \"Recommendation\":\n",
        "            if img_id in predict:\n",
        "                ax.patch.set_edgecolor(\"green\")\n",
        "                ax.patch.set_linewidth(\"5\")\n",
        "                if SHOW_FILENAME:\n",
        "                    ax.set_title(img_fn, color=\"green\")\n",
        "                else:\n",
        "                    ax.set_title(\"Ground truth\", color=\"green\")\n",
        "            elif img_id in profile:\n",
        "                ax.patch.set_edgecolor(\"red\")\n",
        "                ax.patch.set_linewidth(\"5\")\n",
        "                if SHOW_FILENAME:\n",
        "                    ax.set_title(img_fn, color=\"red\")\n",
        "                else:\n",
        "                    ax.set_title(\"Consumed\", color=\"red\")\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZcYoVOwall2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}